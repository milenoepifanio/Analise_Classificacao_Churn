# Previs√£o de Aprova√ß√£o de Empr√©stimo Banc√°rio

Este projeto tem como objetivo prever a aprova√ß√£o de empr√©stimos banc√°rios com base em caracter√≠sticas dos solicitantes, utilizando t√©cnicas de an√°lise explorat√≥ria e algoritmos de aprendizado supervisionado.

## üß† Problema de Neg√≥cio

Melhorar o processo de aprova√ß√£o de cr√©dito pessoal por meio de modelos preditivos, reduzindo decis√µes manuais e imprecisas na concess√£o de empr√©stimos.

## üìö Dicion√°rio de Dados

O dataset possui 14 colunas e 5.000 registros, com atributos como idade, renda, escolaridade, gastos com cart√£o e presen√ßa de produtos banc√°rios. A vari√°vel-alvo √© `Personal Loan`, indicando se o empr√©stimo foi aprovado.


## üìÇ Dataset
O dataset √© obtido automaticamente via KaggleHub a partir do reposit√≥rio:

[Bank Loan Approval - Kaggle](https://www.kaggle.com/datasets/vikramamin/bank-loan-approval-lr-dt-rf-and-auc).


# Prepara√ß√£o do projeto

## üìÅ Estrutura do Projeto

- `download_data.py`: Script para download e salvamento do dataset diretamente do Kaggle utilizando `kagglehub`.
- `EDA.ipynb`: Notebook de An√°lise Explorat√≥ria de Dados (EDA), com visualiza√ß√µes, limpeza e tratamento da base.
- `Models.ipynb`: Notebook de modelagem, compara√ß√£o de algoritmos de classifica√ß√£o e avalia√ß√£o de desempenho.


## üìÇ Estrutura de Pastas

```bash
‚îú‚îÄ‚îÄ data/                      # Cont√©m os dados brutos e processados
‚îÇ   ‚îú‚îÄ‚îÄ dados_banco.csv
‚îÇ   ‚îî‚îÄ‚îÄ dados_banco.parquet
‚îÇ
‚îú‚îÄ‚îÄ outputs/                   # Resultados gerados pelo modelo
‚îÇ   ‚îî‚îÄ‚îÄ resultado_treino_modelos.csv
‚îÇ
‚îú‚îÄ‚îÄ scr/                       # Scripts e notebooks do projeto
‚îÇ   ‚îú‚îÄ‚îÄ download_data.py       # Script de download dos dados
‚îÇ   ‚îú‚îÄ‚îÄ EDA.ipynb              # An√°lise explorat√≥ria de dados
‚îÇ   ‚îî‚îÄ‚îÄ Models.ipynb           # Modelagem e avalia√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ LICENSE.txt
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ pyproject.toml
```

## ‚öôÔ∏è Tecnologias e Bibliotecas

- Linguagem: Python
- Bibliotecas:
  - pandas: Manipula√ß√£o de dados em tabelas (DataFrames).
  - numpy: Opera√ß√µes num√©ricas e vetoriais.
  - seaborn e matplotlib: Visualiza√ß√£o de dados (gr√°ficos).
  - scikit-learn: Algoritmos de machine learning e ferramentas de pr√©-processamento.
  - xgboost, lightgbm: Algoritmos avan√ßados de boosting.
  - joblib: Salvamento e carregamento de modelos.
  - kagglehub: Download de datasets diretamente do Kaggle.


# Explora√ß√£o e Modelagem

## üìä Insights da An√°lise Explorat√≥ria (EDA)

- A base √© desbalanceada: 90% dos clientes n√£o t√™m empr√©stimo aprovado.
- Aprovados t√™m, em m√©dia, **maior renda**, **maior gasto com cart√£o** e **possuem conta CD**.
- Vari√°veis-chave: `Income`, `CCAvg`, `CD.Account`, `Education` e `Mortgage`.
- Forte correla√ß√£o entre `Income`, `CCAvg` e aprova√ß√£o (`Personal.Loan`).
- Dados com outliers significativos e alguns valores inv√°lidos (ex: experi√™ncia negativa).


## üìà Avalia√ß√µes Realizadas

- **Acur√°cia**: Propor√ß√£o de previs√µes corretas sobre o total de previs√µes realizadas.
- **Precis√£o**: Propor√ß√£o de positivos previstos que realmente s√£o positivos (foco em evitar falsos positivos).
- **Recall**: Propor√ß√£o de positivos reais que foram corretamente identificados (foco em evitar falsos negativos).
- **F1-Score**: M√©dia harm√¥nica entre precis√£o e recall, √∫til para dados desbalanceados.
- **ROC-AUC**: Mede a capacidade do modelo em distinguir entre classes, variando de 0.5 (aleat√≥rio) a 1 (perfeito).


## üß™ Modelos Utilizados

- **Regress√£o Log√≠stica**.
- **√Årvore de Decis√£o**.
- **Random Forest**.
- **Gradient Boosting**.
- **XGBoost**.
- **LightGBM**.
- **SVM (Support Vector Machine)**.
- **KNN (K-Nearest Neighbors)**.
- **Naive Bayes**.


## Modelagem e Resultados

- **Pr√©-processamento**:
  - Divis√£o treino/teste em 80/20.
  - Codifica√ß√£o da vari√°vel `Education` via One Hot Encoding.
  - Escalonamento com RobustScaler (mais robusto a outliers).

- **Modelos com melhor desempenho**:
  - **HistGradientBoosting, LightGBM e RandomForest**: Acur√°cia > 99%, AUC ~0.999.
  - **XGBoost, ExtraTrees e Bagging**: Alta performance e estabilidade.
  - Modelos mais simples (Logistic, NaiveBayes, Ridge) tiveram recall baixo.

- **Vari√°veis mais importantes**:
  - `Income`: Mais relevante em quase todos os modelos.
  - `CCAvg`: Destaque no LightGBM e RandomForest, menos valorizado no HistGradientBoosting.
  - `Education`: Relevante em alguns modelos, mas impacto vari√°vel.

- **Perfil dos algoritmos**:
  - HistGradientBoosting foca em menos vari√°veis (mais concentrado).
  - LightGBM distribui import√¢ncia entre mais vari√°veis (maior sensibilidade).

# Execu√ß√£o e Expectativas

## üì¶ Como Executar

1. Clone o reposit√≥rio:
```bash
git clone https://github.com/seu-usuario/seu-projeto.git
cd seu-projeto
```

2. Instale as depend√™ncias:
```bash
pip install -r requirements.txt
```

3. Execute o download do dataset:
```bash
python scr/download_data.py
```

4. Explore os notebooks:
```bash
- notebooks/EDA.ipynb
- notebooks/Models.ipynb
```

# Resultados Esperados

Este projeto busca entender os fatores que influenciam a concess√£o de cr√©dito e desenvolver modelos preditivos robustos que auxiliem na tomada de decis√£o automatizada e mais justa.

## Licen√ßa

Este projeto est√° licenciado sob a [Creative Commons BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/deed.pt_BR).  
Voc√™ pode usar, compartilhar e adaptar, **desde que cite a autoria (Mileno Epifanio)** e **n√£o utilize para fins comerciais**.
